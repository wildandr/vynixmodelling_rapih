2025-10-05 14:51:38,120 - INFO - Original dataframe shape: (3816, 14)
2025-10-05 14:51:38,121 - INFO - Total rows in df without NaN or null values: 3783
2025-10-05 14:51:38,285 - INFO - Kolom dengan data lengkap (>= 70.0%): 57
2025-10-05 14:51:38,286 - INFO - Kolom dengan data tidak lengkap (kurang dari 70.0%): 481
2025-10-05 14:51:38,287 - INFO - 
Filtered DataFrame shape: (57, 57)
2025-10-05 14:51:38,288 - INFO - Data completeness setelah filtering: 100.00%
2025-10-05 14:51:38,348 - INFO - 
Enhanced DataFrame shape: (57, 151)
2025-10-05 14:51:38,348 - INFO - Jumlah fitur asli: 57
2025-10-05 14:51:38,348 - INFO - Jumlah fitur baru: 94
2025-10-05 14:51:38,348 - INFO - Total fitur: 151
2025-10-05 14:51:38,348 - INFO - 
Statistik Enhanced DataFrame:
2025-10-05 14:51:38,349 - INFO - Data completeness: 98.95%
2025-10-05 14:51:38,355 - INFO - Kolom dengan data tidak lengkap di Enhanced DataFrame: 39
2025-10-05 14:51:38,382 - INFO - 
Enhanced DataFrame saved to: datasets/fundamental/TSLA_enhanced_features.csv
2025-10-05 14:51:38,383 - INFO - DataFrame setelah filter q > 2012-Q1: (53, 151)
2025-10-05 14:51:38,384 - INFO - Data completeness: 100.00%
2025-10-05 14:51:38,384 - INFO - Processing technical and fundamental data...
2025-10-05 14:51:38,385 - INFO - Starting complete preprocessing pipeline with quarter shift mapping
2025-10-05 14:51:38,385 - INFO - Preparing technical data
2025-10-05 14:51:38,391 - INFO - Technical data prepared: 3783 rows, 17 columns
2025-10-05 14:51:38,392 - INFO - Preparing fundamental data
2025-10-05 14:51:38,392 - INFO - Fundamental data prepared: 53 quarters, 151 features
2025-10-05 14:51:38,392 - INFO - Converting quarterly data to daily format with quarter shift mapping
2025-10-05 14:51:42,047 - INFO - Daily conversion completed: 4839 days, 151 features
2025-10-05 14:51:42,047 - INFO - Data availability with quarter shift mapping: 98.12%
2025-10-05 14:51:42,048 - INFO - Combining technical and fundamental data
2025-10-05 14:51:42,064 - INFO - Data combination completed: 3330 rows, 168 columns
2025-10-05 14:51:42,066 - INFO - Date range: 2012-04-02 to 2025-06-30
2025-10-05 14:51:42,066 - INFO - Filtering data from 2012-Q2 to 2025-Q2
2025-10-05 14:51:42,071 - INFO - Filtering completed: 3330 rows remaining
2025-10-05 14:51:42,072 - INFO - Saving processed data to: datasets/processed/main_processed_data.csv
2025-10-05 14:51:43,270 - INFO - Data saved successfully: 3330 rows, 168 columns
2025-10-05 14:51:43,270 - INFO - Complete preprocessing pipeline finished successfully
2025-10-05 14:51:43,271 - INFO - Data processing completed: (3330, 168)
2025-10-05 14:51:43,271 - INFO - Processed data saved to: datasets/processed/main_processed_data.csv
2025-10-05 14:51:43,271 - INFO - 
Final processed data shape: (3330, 168)
2025-10-05 14:51:43,272 - INFO - Date range: 2012-04-02 00:00:00 to 2025-06-30 00:00:00
2025-10-05 14:51:43,272 - INFO - Technical columns: 8
2025-10-05 14:51:43,273 - INFO - Fundamental columns: 157
2025-10-05 14:51:43,273 - INFO - 
Preprocessing completed successfully!
2025-10-05 14:51:43,276 - INFO - Data completeness: 98.30%
2025-10-05 14:51:43,276 - INFO - 
=== Applying Triple Barrier Method ===
2025-10-05 14:51:43,276 - INFO - Starting Triple Barrier Method labeling...
2025-10-05 14:51:44,305 - INFO - 
=== Generating Triple Barrier Visualizations ===
2025-10-05 14:51:44,306 - INFO - Generating Triple Barrier visualizations...
2025-10-05 14:51:44,582 - INFO - Visualizations generated: 2 files
2025-10-05 14:51:44,583 - INFO - label_1_html: logs/visualization/visualisasi_20251005_145144_label_positif.html
2025-10-05 14:51:44,583 - INFO - label_-1_html: logs/visualization/visualisasi_20251005_145144_label_negatif.html
2025-10-05 14:51:44,583 - INFO - 
=== Triple Barrier Implementation Complete ===
2025-10-05 14:51:44,583 - INFO - Labels generated: 3314 samples
2025-10-05 14:51:44,583 - INFO - Results saved to: logs/triple_barrier/triple_barrier_results.csv
2025-10-05 14:51:44,583 - INFO - 
=== Merging Triple Barrier Labels with Features ===
2025-10-05 14:51:44,583 - INFO - Merging triple_barrier_df with filtered_df based on decision_date...
2025-10-05 14:51:44,602 - INFO - Triple Barrier data shape: (3314, 11)
2025-10-05 14:51:44,602 - INFO - Filtered data shape: (3330, 168)
2025-10-05 14:51:44,602 - INFO - Merged data shape: (3314, 178)
2025-10-05 14:51:44,605 - INFO - Successfully merged: 3251 complete rows
2025-10-05 14:51:45,967 - INFO - Merged labeled data saved to: datasets/processed/merged_labeled_data.csv
2025-10-05 14:51:45,967 - INFO - 
=== Final Summary ===
2025-10-05 14:51:45,967 - INFO - Original processed data shape: (3330, 168)
2025-10-05 14:51:45,967 - INFO - Triple Barrier labels: 3314 samples
2025-10-05 14:51:45,967 - INFO - Merged labeled data shape: (3314, 178)
2025-10-05 14:51:45,967 - INFO - Date range: 2012-04-02 00:00:00 to 2025-06-30 00:00:00
2025-10-05 14:51:45,968 - INFO - Date range: 2012-04-02 00:00:00 to 2025-06-05 00:00:00
2025-10-05 14:51:45,968 - INFO - Technical + Fundamental features: 168 columns
2025-10-05 14:51:45,968 - INFO - Total features in merged data: 178 columns
2025-10-05 14:51:45,968 - INFO - Triple Barrier parameters used: {'volatility_window': 20, 'upper_barrier_multiplier': 1.0, 'lower_barrier_multiplier': 1.0, 'time_barrier_days': 15, 'verbose': True}
2025-10-05 14:51:45,968 - INFO - 
All preprocessing, labeling, and merging completed successfully!
2025-10-05 14:51:45,970 - INFO - Dropped columns: ['decision_date', 'entry_date', 'end_date', 'end_price', 'return', 'barrier_touched', 'value_at_barrier_touched', 'time_converted', 'datetime', 'time']
2025-10-05 14:51:45,970 - INFO - Training DataFrame shape after dropping columns: (3314, 168)
2025-10-05 14:51:45,970 - INFO - Training DataFrame columns: ['entry_price', 'upper_barrier', 'lower_barrier', 'label', 'open', 'high', 'low', 'close', 'Volume', 'Histogram', 'MACD', 'Signal', 'K', 'D', 'Turnover (Cr)', '10 MA Turnover', 'Turnover / 10MA (X)', 'AccountsPayableCurrent', 'AccountsReceivableNetCurrent', 'AccumulatedDepreciationDepletionAndAmortizationPropertyPlantAndEquipment', 'AccumulatedOtherComprehensiveIncomeLossNetOfTax', 'AdditionalPaidInCapitalCommonStock', 'AllocatedShareBasedCompensationExpense', 'Assets', 'AssetsCurrent', 'CashAndCashEquivalentsAtCarryingValue', 'CommonStockValue', 'ComprehensiveIncomeNetOfTax', 'CostOfRevenue', 'EmployeeRelatedLiabilitiesCurrent', 'GrossProfit', 'IncomeLossFromContinuingOperationsBeforeIncomeTaxesExtraordinaryItemsNoncontrollingInterest', 'IncomeTaxExpenseBenefit', 'IncreaseDecreaseInAccountsPayableAndAccruedLiabilities', 'IncreaseDecreaseInAccountsReceivable', 'IncreaseDecreaseInOtherNoncurrentLiabilities', 'IncreaseDecreaseInPrepaidDeferredExpenseAndOtherAssets', 'InterestCostsCapitalized', 'InterestExpense', 'InventoryNet', 'InventoryWriteDown', 'InvestmentIncomeInterest', 'Liabilities', 'LiabilitiesAndStockholdersEquity', 'LiabilitiesCurrent', 'NetCashProvidedByUsedInFinancingActivities', 'NetCashProvidedByUsedInInvestingActivities', 'NetCashProvidedByUsedInOperatingActivities', 'NetIncomeLoss', 'NoncashOrPartNoncashAcquisitionValueOfAssetsAcquired1', 'NoncurrentAssets', 'OperatingExpenses', 'OperatingIncomeLoss', 'OtherAssetsNoncurrent', 'OtherComprehensiveIncomeLossForeignCurrencyTransactionAndTranslationAdjustmentNetOfTax', 'OtherLiabilitiesNoncurrent', 'OtherNonoperatingIncomeExpense', 'PaymentsToAcquirePropertyPlantAndEquipment', 'PrepaidExpenseAndOtherAssetsCurrent', 'ProceedsFromIssuanceOfSharesUnderIncentiveAndShareBasedCompensationPlansIncludingStockOptions', 'ProductWarrantyAccrualPreexistingIncreaseDecrease', 'PropertyPlantAndEquipmentGross', 'PropertyPlantAndEquipmentNet', 'ResearchAndDevelopmentExpense', 'RetainedEarningsAccumulatedDeficit', 'Revenues', 'SellingGeneralAndAdministrativeExpense', 'ShareBasedCompensation', 'StandardProductWarrantyAccrual', 'StandardProductWarrantyAccrualPayments', 'StandardProductWarrantyAccrualWarrantiesIssued', 'StockholdersEquity', 'TaxesPayableCurrent', 'UnrecognizedTaxBenefits', 'current_ratio', 'quick_ratio', 'cash_ratio', 'working_capital', 'accounts_receivable_turnover', 'days_sales_outstanding', 'inventory_turnover', 'days_inventory_outstanding', 'accounts_payable_turnover', 'days_payable_outstanding', 'cash_conversion_cycle', 'gross_profit_margin', 'operating_profit_margin', 'net_profit_margin', 'return_on_assets', 'return_on_equity', 'debt_to_equity_ratio', 'debt_to_assets_ratio', 'interest_coverage_ratio', 'operating_expense_ratio', 'rd_to_revenue_ratio', 'sga_to_revenue_ratio', 'fixed_asset_turnover', 'total_asset_turnover', 'capital_expenditure_ratio', 'compensation_efficiency', 'warranty_reserve_ratio', 'depreciation_rate', 'operating_cash_flow_to_net_income_ratio', 'effective_tax_rate', 'revenue_growth_rate', 'net_income_growth_rate', 'asset_growth_rate', 'accrual_ratio', 'cash_flow_to_revenue_ratio', 'return_on_invested_capital', 'cash_return_on_capital_invested', 'fixed_assets_to_long_term_debt_ratio', 'non_current_asset_turnover', 'quarterly_gross_profit_stability', 'revenue_to_expense_growth_differential', 'quarterly_cash_flow_quality', 'dividend_payout_ratio', 'stock_based_compensation_to_operating_expense_ratio', 'financial_leverage_index', 'asset_coverage_ratio', 'quarterly_margin_expansion', 'asset_utilization_ratio', 'capacity_utilization_proxy', 'altman_z_score', 'dupont_analysis_roe', 'economic_value_added', 'rd_efficiency_ratio', 'innovation_investment_ratio', 'revenue_momentum', 'earnings_momentum', 'quarterly_earnings_quality_index', 'non_operating_items_ratio', 'revenues_qoq_growth', 'revenues_yoy_growth', 'revenues_ttm', 'revenues_acceleration', 'revenues_seasonal_index', 'revenues_moving_avg', 'revenues_run_rate', 'revenues_volatility', 'revenues_seasonal_dependency', 'net_income_qoq_growth', 'net_income_yoy_growth', 'net_income_ttm', 'net_income_acceleration', 'net_income_seasonal_index', 'net_income_moving_avg', 'net_income_run_rate', 'net_income_volatility', 'assets_qoq_growth', 'assets_yoy_growth', 'assets_ttm', 'operating_income_qoq_growth', 'operating_income_yoy_growth', 'operating_income_ttm', 'cash_qoq_growth', 'cash_yoy_growth', 'equity_qoq_growth', 'equity_yoy_growth', 'liabilities_qoq_growth', 'liabilities_yoy_growth', 'quarterly_operating_leverage', 'quarterly_cash_burn_rate', 'revenues_ytd', 'netincomeloss_ytd', 'operatingincomeloss_ytd', 'long_term_revenue_cagr', 'operating_margin_trend']
2025-10-05 14:51:45,971 - INFO - 
=== Splitting Data into Train, Validation, and Test Sets (Time-based) ===
2025-10-05 14:51:45,971 - INFO - Splitting data into train, validation, and test sets using time-based approach...
2025-10-05 14:51:45,989 - INFO - Test data period: 2024-07-01 00:00:00 to 2025-06-05 00:00:00
2025-10-05 14:51:45,990 - INFO - Test data shape: (234, 178)
2025-10-05 14:51:45,993 - INFO - Train+Val data period: 2012-04-02 00:00:00 to 2024-06-28 00:00:00
2025-10-05 14:51:45,993 - INFO - Train+Val data shape: (3080, 178)
2025-10-05 14:51:46,008 - INFO - X_train shape: (2464, 167), y_train shape: (2464,)
2025-10-05 14:51:46,008 - INFO - X_test shape: (234, 167), y_test shape: (234,)
2025-10-05 14:51:46,009 - INFO - X_val shape: (616, 167), y_val shape: (616,)
2025-10-05 14:51:47,297 - INFO - Train, test, and validation data saved to datasets/training_data
2025-10-05 14:51:47,297 - INFO - 8. HYPERPARAMETER TUNING
2025-10-05 14:51:47,297 - INFO - ================================================================================
2025-10-05 14:51:47,351 - INFO - 
Combined HMM, XGBoost, and Barrier Parameters Tuning with Optuna
2025-10-05 14:51:47,351 - INFO - --------------------------------------------------
2025-10-05 14:51:47,351 - INFO - Combined HMM, XGBoost, and LSTM Parameters Tuning with Optuna
2025-10-05 14:51:47,351 - INFO - --------------------------------------------------
2025-10-05 14:51:47,352 - INFO - TensorFlow available - using XGB-HMM-LSTM hybrid optimization
2025-10-05 14:51:47,352 - INFO - Starting combined_xgb_hmm_lstm_barrier_parameters optimization with Optuna...
2025-10-05 14:51:47,913 - INFO - Study 'combined_xgb_hmm_lstm_barrier_parameters' created/loaded with storage: logs/optuna_studies/combined_xgb_hmm_lstm_barrier_parameters.db
2025-10-05 14:51:49,368 - INFO - Starting XGB-HMM training with 2 states for 2 classes...
2025-10-05 14:51:49,369 - INFO - Initializing GMM-HMM for state estimation...
2025-10-05 14:51:50,021 - INFO - Training initial XGBoost model with GMM-derived states...
2025-10-05 14:54:04,599 - INFO - Converged after 85 iterations
2025-10-05 14:54:04,599 - INFO - XGB-HMM training completed
2025-10-05 14:54:04,645 - INFO - Combined Parameters Optimization - Trial 52: New best score 0.5633
2025-10-05 14:54:04,666 - INFO - 
Combined hyperparameter tuning completed in 137.31 seconds
2025-10-05 14:54:04,666 - INFO - Best combined validation accuracy: 0.8815
2025-10-05 14:54:04,666 - INFO - Best trial number: 26
2025-10-05 14:54:04,666 - INFO - 
Best HMM Parameters:
2025-10-05 14:54:04,666 - INFO -   n_states: 3
2025-10-05 14:54:04,666 - INFO -   max_iter: 700
2025-10-05 14:54:04,666 - INFO -   tol: 8.900876447967033e-06
2025-10-05 14:54:04,666 - INFO - 
Best XGBoost Parameters:
2025-10-05 14:54:04,666 - INFO -   n_estimators: 100
2025-10-05 14:54:04,667 - INFO -   max_depth: 8
2025-10-05 14:54:04,667 - INFO -   learning_rate: 0.06397033011773137
2025-10-05 14:54:04,667 - INFO -   subsample: 0.9
2025-10-05 14:54:04,667 - INFO -   colsample_bytree: 0.9
2025-10-05 14:54:04,667 - INFO -   reg_alpha: 8.1
2025-10-05 14:54:04,667 - INFO -   reg_lambda: 1.9
2025-10-05 14:54:04,667 - INFO -   min_child_weight: 7
2025-10-05 14:54:04,667 - INFO -   gamma: 4.4
2025-10-05 14:54:04,667 - INFO - 
Best LSTM Parameters:
2025-10-05 14:54:04,667 - INFO -   sequence_length: 400
2025-10-05 14:54:04,667 - INFO -   lstm_units: 432
2025-10-05 14:54:04,667 - INFO -   dropout_rate: 0.32
2025-10-05 14:54:04,667 - INFO -   learning_rate: 0.0005655332644067792
2025-10-05 14:54:04,667 - INFO - 
Best Ensemble Weights: XGB=0.20, HMM=0.28, LSTM=0.52
2025-10-05 14:54:04,668 - INFO - 
Best Barrier Parameters:
2025-10-05 14:54:04,668 - INFO -   volatility_window: 50
2025-10-05 14:54:04,668 - INFO -   upper_barrier_multiplier: 2.4000000000000004
2025-10-05 14:54:04,668 - INFO -   lower_barrier_multiplier: 2.4000000000000004
2025-10-05 14:54:04,668 - INFO -   time_barrier_days: 35
2025-10-05 14:54:04,687 - INFO - Optimization summary saved to: logs/xgb_results/combined_optimization_summary.pkl
2025-10-05 14:54:04,687 - INFO - 
Using best parameters from combined tuning for final model training...
2025-10-05 14:54:04,687 - INFO - Applying triple barrier labeling with optimized parameters...
2025-10-05 14:54:06,319 - INFO - Updated merged data with optimized barrier parameters: (3294, 178)
2025-10-05 14:54:06,319 - INFO - 
9. Training XGB-HMM Hybrid Model
2025-10-05 14:54:06,319 - INFO - --------------------------------------------------
2025-10-05 14:54:06,319 - INFO - Using existing triple barrier data for XGB-HMM training...
2025-10-05 14:54:06,319 - INFO - Triple barrier data already available: 3314 samples
2025-10-05 14:54:06,320 - INFO - Proceeding directly to XGB-HMM training with existing merged data...
2025-10-05 14:54:06,323 - INFO - Final dataset shape: (3294, 178)
2025-10-05 14:54:06,323 - INFO - Label distribution:
2025-10-05 14:54:06,324 - INFO - label
-1    1397
 0      17
 1    1880
Name: count, dtype: int64
2025-10-05 14:54:06,329 - INFO - Final test data period: 2024-07-01 00:00:00 to 2025-05-07 00:00:00
2025-10-05 14:54:06,329 - INFO - Final test data shape: (214, 178)
2025-10-05 14:54:06,332 - INFO - Final train+val data period: 2012-04-02 00:00:00 to 2024-06-28 00:00:00
2025-10-05 14:54:06,332 - INFO - Final train+val data shape: (3080, 178)
2025-10-05 14:54:06,338 - INFO - 
Final data splits:
2025-10-05 14:54:06,338 - INFO - Training set: 2464 samples
2025-10-05 14:54:06,338 - INFO - Validation set: 616 samples
2025-10-05 14:54:06,338 - INFO - Test set: 214 samples
2025-10-05 14:54:06,339 - INFO - 
Final label mapping: {np.int64(-1): 0, np.int64(0): 1, np.int64(1): 2}
2025-10-05 14:54:06,339 - INFO - Number of classes: 3
2025-10-05 14:54:06,339 - INFO - 
=== Applying Feature Selection ===
2025-10-05 14:54:06,339 - INFO - Initializing feature selection process...
2025-10-05 14:54:06,340 - INFO - Original number of features: 167
2025-10-05 14:54:06,340 - INFO - Applying ensemble feature selection...
2025-10-05 14:54:06,340 - INFO - Performing ensemble feature selection...
2025-10-05 14:54:06,340 - INFO - Performing univariate feature selection with k=83 features...
2025-10-05 14:54:06,356 - INFO - Univariate selection completed. Selected 83 features.
2025-10-05 14:54:06,356 - INFO - Performing mutual information feature selection with k=83 features...
2025-10-05 14:54:07,901 - INFO - Mutual information selection completed. Selected 83 features.
2025-10-05 14:54:07,902 - INFO - Performing RFE selection with n_features=83...
2025-10-05 14:54:42,937 - INFO - RFE selection completed. Selected 83 features.
2025-10-05 14:54:42,937 - INFO - Performing feature importance selection with n_features=83...
2025-10-05 14:54:45,131 - INFO - Feature importance selection completed. Selected 83 features.
2025-10-05 14:54:45,132 - INFO - Ensemble selection completed. Selected 112 features with 2+ votes.
2025-10-05 14:54:45,132 - INFO - Selected 112 features out of 167
2025-10-05 14:54:45,132 - INFO - Feature reduction: 32.93%
2025-10-05 14:54:45,133 - INFO - 
Feature Selection Summary:
2025-10-05 14:54:45,133 - INFO - Applying feature selection to training, validation, and test sets...
2025-10-05 14:54:45,141 - INFO - Selected feature names (top 10): ['entry_price', 'upper_barrier', 'lower_barrier', 'open', 'high', 'low', 'close', 'Histogram', 'MACD', 'Signal']
2025-10-05 14:54:45,142 - INFO - ... and 102 more features
2025-10-05 14:54:45,145 - INFO - Feature selection summary saved to: logs/xgb_results/feature_selection_summary.pkl
2025-10-05 14:54:45,145 - INFO - 
=== Training XGB-HMM-LSTM Triple Hybrid Model with Selected Features ===
2025-10-05 14:54:45,145 - INFO - Initializing XGB-HMM-LSTM model with optimal parameters and selected features...
2025-10-05 14:54:45,145 - INFO - XGB-HMM-LSTM Model initialized with optimized parameters
2025-10-05 14:54:45,145 - INFO -   n_states: 3
2025-10-05 14:54:45,145 - INFO -   max_iter: 700
2025-10-05 14:54:45,145 - INFO -   tol: 8.900876447967033e-06
2025-10-05 14:54:45,145 - INFO -   sequence_length: 400
2025-10-05 14:54:45,145 - INFO -   lstm_units: 432
2025-10-05 14:54:45,145 - INFO -   ensemble_weights: [0.2, 0.28, 0.52]
2025-10-05 14:54:45,145 - INFO -   TensorFlow available: True
2025-10-05 14:54:45,146 - INFO - Starting XGB-HMM-LSTM training with EM algorithm...
2025-10-05 14:54:45,146 - INFO - Starting XGB-HMM training with 3 states for 3 classes...
2025-10-05 14:54:45,146 - INFO - Initializing GMM-HMM for state estimation...
2025-10-05 14:54:45,655 - INFO - Training initial XGBoost model with GMM-derived states...
2025-10-05 15:23:33,717 - INFO - Maximum iterations (700) reached
2025-10-05 15:23:33,717 - INFO - XGB-HMM training completed
2025-10-05 15:23:33,717 - INFO - Training LSTM model...
2025-10-05 15:23:33,717 - INFO - Preparing sequences for LSTM with sequence_length=400
2025-10-05 15:23:33,996 - INFO - Created 2064 sequences for LSTM training
2025-10-05 15:23:33,997 - INFO - Sequence shape: (2064, 400, 112)
2025-10-05 15:23:36,488 - INFO - Number of classes for LSTM: 3
2025-10-05 15:23:36,612 - INFO - Data range after scaling: [0.0000, 1.0000]
2025-10-05 15:23:36,786 - ERROR - Error training LSTM model: Only one of `clipnorm`, `clipvalue` and `global_clipnorm` can be set. Received: clipnorm=1.0, clipvalue=0.5, global_clipnorm=None
2025-10-05 15:23:36,786 - ERROR - LSTM training error details:
Traceback (most recent call last):
  File "/root/vynixmodelling_rapih/xgb_hmm_lstm.py", line 908, in _train_lstm_model
    optimizer = Adam(learning_rate=self.learning_rate, clipnorm=1.0, clipvalue=0.5)
  File "/root/vynixmodelling_rapih/venv/lib/python3.10/site-packages/keras/src/optimizers/adam.py", line 62, in __init__
    super().__init__(
  File "/root/vynixmodelling_rapih/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py", line 21, in __init__
    super().__init__(*args, **kwargs)
  File "/root/vynixmodelling_rapih/venv/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py", line 134, in __init__
    raise ValueError(
ValueError: Only one of `clipnorm`, `clipvalue` and `global_clipnorm` can be set. Received: clipnorm=1.0, clipvalue=0.5, global_clipnorm=None
2025-10-05 15:23:36,788 - WARNING - LSTM disabled due to error. Adjusted ensemble weights to XGB=0.42, HMM=0.58, LSTM=0.00
2025-10-05 15:23:36,799 - INFO - XGB-HMM-LSTM training completed in 1731.65 seconds
2025-10-05 15:23:36,799 - WARNING - LSTM model not available, using XGB-HMM only
2025-10-05 15:23:36,799 - INFO - 
=== XGB-HMM-LSTM Model Detailed Evaluation ===
2025-10-05 15:23:37,669 - INFO - XGB-HMM Evaluation Metrics:
2025-10-05 15:23:37,669 - INFO -   Log Likelihood: -1700.8070
2025-10-05 15:23:37,669 - INFO -   Perplexity: 1.9942
2025-10-05 15:23:37,669 - INFO -   State Sequence Accuracy: 0.9761
2025-10-05 15:23:37,669 - INFO -   Emission Accuracy: 0.9984
2025-10-05 15:23:37,669 - INFO -   Avg Log Likelihood per Sample: -0.6903
2025-10-05 15:23:37,669 - INFO - 
Training Set XGB-HMM-LSTM Evaluation:
2025-10-05 15:23:37,669 - INFO -   log_likelihood: -1700.8070
2025-10-05 15:23:37,669 - INFO -   perplexity: 1.9942
2025-10-05 15:23:37,670 - INFO -   state_sequence_accuracy: 0.9761
2025-10-05 15:23:37,670 - INFO -   emission_accuracy: 0.9984
2025-10-05 15:23:37,670 - INFO -   avg_log_likelihood_per_sample: -0.6903
2025-10-05 15:23:37,905 - INFO - XGB-HMM Evaluation Metrics:
2025-10-05 15:23:37,905 - INFO -   Log Likelihood: -413.2615
2025-10-05 15:23:37,905 - INFO -   Perplexity: 1.9560
2025-10-05 15:23:37,905 - INFO -   State Sequence Accuracy: 0.8912
2025-10-05 15:23:37,906 - INFO -   Emission Accuracy: 0.8912
2025-10-05 15:23:37,906 - INFO -   Avg Log Likelihood per Sample: -0.6709
2025-10-05 15:23:37,906 - INFO - 
Validation Set XGB-HMM-LSTM Evaluation:
2025-10-05 15:23:37,906 - INFO -   log_likelihood: -413.2615
2025-10-05 15:23:37,906 - INFO -   perplexity: 1.9560
2025-10-05 15:23:37,906 - INFO -   state_sequence_accuracy: 0.8912
2025-10-05 15:23:37,906 - INFO -   emission_accuracy: 0.8912
2025-10-05 15:23:37,906 - INFO -   avg_log_likelihood_per_sample: -0.6709
2025-10-05 15:23:38,004 - INFO - XGB-HMM Evaluation Metrics:
2025-10-05 15:23:38,004 - INFO -   Log Likelihood: -182.6533
2025-10-05 15:23:38,004 - INFO -   Perplexity: 2.3479
2025-10-05 15:23:38,004 - INFO -   State Sequence Accuracy: 0.5327
2025-10-05 15:23:38,004 - INFO -   Emission Accuracy: 0.5280
2025-10-05 15:23:38,004 - INFO -   Avg Log Likelihood per Sample: -0.8535
2025-10-05 15:23:38,004 - INFO - 
Test Set XGB-HMM-LSTM Evaluation:
2025-10-05 15:23:38,004 - INFO -   log_likelihood: -182.6533
2025-10-05 15:23:38,004 - INFO -   perplexity: 2.3479
2025-10-05 15:23:38,004 - INFO -   state_sequence_accuracy: 0.5327
2025-10-05 15:23:38,005 - INFO -   emission_accuracy: 0.5280
2025-10-05 15:23:38,005 - INFO -   avg_log_likelihood_per_sample: -0.8535
2025-10-05 15:23:38,005 - INFO - 
=== State Transition Analysis ===
2025-10-05 15:23:38,014 - INFO - State Transition Analysis:
2025-10-05 15:23:38,015 - INFO -   State Distribution: [0.67757009 0.         0.32242991]
2025-10-05 15:23:38,015 - INFO -   Most Frequent State: 0
2025-10-05 15:23:38,015 - INFO -   Least Frequent State: 1
2025-10-05 15:23:38,015 - INFO - 
Learned Transition Matrix:
2025-10-05 15:23:38,015 - INFO - [[3.73067723e-01 0.00000000e+00 6.26932277e-01]
 [1.00000000e+00 0.00000000e+00 2.42493763e-14]
 [4.17063781e-01 0.00000000e+00 5.82936219e-01]]
2025-10-05 15:23:38,016 - INFO - 
Empirical Transition Matrix:
2025-10-05 15:23:38,016 - INFO - [[0.875      0.         0.125     ]
 [0.         0.         0.        ]
 [0.26086957 0.         0.73913043]]
2025-10-05 15:23:38,016 - INFO - 
Evaluating XGB-HMM-LSTM model on all datasets...
2025-10-05 15:23:38,402 - WARNING - ROC AUC calculation skipped due to class mismatch. Test classes: 2, Proba shape: (214, 3)
2025-10-05 15:23:38,403 - INFO - 
============================================================
2025-10-05 15:23:38,403 - INFO - XGB-HMM-LSTM HYBRID MODEL PERFORMANCE
2025-10-05 15:23:38,403 - INFO - ============================================================
2025-10-05 15:23:38,403 - INFO - 
Training Set Performance:
2025-10-05 15:23:38,403 - INFO - Accuracy: 0.9761
2025-10-05 15:23:38,403 - INFO - Precision: 0.9703
2025-10-05 15:23:38,403 - INFO - Recall: 0.9761
2025-10-05 15:23:38,403 - INFO - F1-Score: 0.9729
2025-10-05 15:23:38,403 - INFO - ROC AUC: 0.8306
2025-10-05 15:23:38,404 - INFO - 
Validation Set Performance:
2025-10-05 15:23:38,404 - INFO - Accuracy: 0.8912
2025-10-05 15:23:38,404 - INFO - Precision: 0.8916
2025-10-05 15:23:38,404 - INFO - Recall: 0.8912
2025-10-05 15:23:38,404 - INFO - F1-Score: 0.8894
2025-10-05 15:23:38,404 - INFO - ROC AUC: 0.7999
2025-10-05 15:23:38,404 - INFO - 
Test Set Performance:
2025-10-05 15:23:38,404 - INFO - Accuracy: 0.5327
2025-10-05 15:23:38,404 - INFO - Precision: 0.5627
2025-10-05 15:23:38,404 - INFO - Recall: 0.5327
2025-10-05 15:23:38,404 - INFO - F1-Score: 0.5188
2025-10-05 15:23:38,405 - INFO - ROC AUC: 0.5327
2025-10-05 15:23:38,405 - INFO - 
Test Set Confusion Matrix:
2025-10-05 15:23:38,406 - INFO - [[71 26]
 [74 43]]
2025-10-05 15:23:38,407 - INFO - 
Test Set Classification Report:
2025-10-05 15:23:38,407 - INFO - Classes in test data: [np.int64(0), np.int64(2)]
2025-10-05 15:23:38,407 - INFO - Classes predicted by model: [np.int64(0), np.int64(2)]
2025-10-05 15:23:38,407 - INFO - All classes for classification report: [np.int64(0), np.int64(2)]
2025-10-05 15:23:38,416 - INFO -               precision    recall  f1-score   support

          -1       0.49      0.73      0.59        97
           1       0.62      0.37      0.46       117

    accuracy                           0.53       214
   macro avg       0.56      0.55      0.52       214
weighted avg       0.56      0.53      0.52       214

2025-10-05 15:23:38,416 - INFO - 
============================================================
2025-10-05 15:23:38,416 - INFO - PERFORMANCE COMPARISON
2025-10-05 15:23:38,416 - INFO - ============================================================
2025-10-05 15:23:38,417 - INFO -       Dataset  Accuracy  Precision  Recall  F1-Score  ROC AUC
0    Training    0.9761     0.9703  0.9761    0.9729   0.8306
1  Validation    0.8912     0.8916  0.8912    0.8894   0.7999
2        Test    0.5327     0.5627  0.5327    0.5188   0.5327
2025-10-05 15:23:38,433 - INFO - 
Final performance comparison saved to: logs/xgb_results/final_performance_comparison.csv
2025-10-05 15:23:38,458 - INFO - XGB-HMM-LSTM model saved to: logs/xgb_models/xgb_hmm_lstm_model.pkl
2025-10-05 15:23:38,461 - INFO - Final test predictions saved to: logs/xgb_results/final_test_predictions.csv
2025-10-05 15:23:38,461 - INFO - 
============================================================
2025-10-05 15:23:38,461 - INFO - XGB-HMM-LSTM HYPERPARAMETER SUMMARY
2025-10-05 15:23:38,461 - INFO - ============================================================
2025-10-05 15:23:38,461 - INFO - 
XGB-HMM-LSTM Model Parameters:
2025-10-05 15:23:38,462 - INFO -   n_states: 3
2025-10-05 15:23:38,462 - INFO -   max_iter: 700
2025-10-05 15:23:38,462 - INFO -   tolerance: 8.900876447967033e-06
2025-10-05 15:23:38,462 - INFO -   random_state: 42
2025-10-05 15:23:38,462 - INFO - 
XGB-HMM-LSTM Training Summary:
2025-10-05 15:23:38,462 - INFO -   Training time: 1731.65 seconds
2025-10-05 15:23:38,462 - INFO -   Convergence achieved: False
2025-10-05 15:23:38,462 - INFO -   Final log-likelihood: N/A
2025-10-05 15:23:38,462 - INFO - 
Hybrid XGB-HMM vs Original XGBoost Performance:
2025-10-05 15:23:38,462 - INFO - Original XGBoost Test Accuracy: ~0.45 (from previous runs)
2025-10-05 15:23:38,462 - INFO - Hybrid XGB-HMM Test Accuracy: 0.5327
2025-10-05 15:23:38,462 - INFO - Performance Improvement: 18.38%
2025-10-05 15:23:38,463 - INFO - 
Hybrid XGB-HMM Model Generalization:
2025-10-05 15:23:38,463 - INFO - Training Accuracy: 0.9761
2025-10-05 15:23:38,463 - INFO - Validation Accuracy: 0.8912
2025-10-05 15:23:38,463 - INFO - Test Accuracy: 0.5327
2025-10-05 15:23:38,463 - INFO - Train-Val Gap: 0.0848
2025-10-05 15:23:38,463 - INFO - Train-Test Gap: 0.4433
2025-10-05 15:23:38,463 - INFO - 
=== Feature Selection Impact Analysis ===
2025-10-05 15:23:38,463 - INFO - Original features: 167
2025-10-05 15:23:38,463 - INFO - Selected features: 112
2025-10-05 15:23:38,463 - INFO - Feature reduction: 32.93%
2025-10-05 15:23:38,463 - INFO - Model performance maintained with 67.07% of original features
2025-10-05 15:23:38,463 - INFO - 
================================================================================
2025-10-05 15:23:38,464 - INFO - XGB-HMM-LSTM HYBRID MODEL WITH FEATURE SELECTION COMPLETED SUCCESSFULLY!
2025-10-05 15:23:38,464 - INFO - ================================================================================
